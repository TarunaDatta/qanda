{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to load the json files for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train-v2.0.json\"\n",
    "val_path = \"dev-v2.0.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_path)\n",
    "data = train_data[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the word2vec model into memory here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each question in the dataset we compare each sentence in their respective context using the word mover's distance, a measure of the earth mover's distance for the word vectors between two sentences, and identify the sentence with the lowest score (most similar).\n",
    "\n",
    "We record whether the answer (according to the dataset) is present in the sentence or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [1:08:34<00:00,  9.31s/it]\n"
     ]
    }
   ],
   "source": [
    "ans_in_sim = []\n",
    "for topic in tqdm(train_data[\"data\"]):\n",
    "    for para in topic[\"paragraphs\"]:\n",
    "        context = para[\"context\"]\n",
    "        sents = nltk.tokenize.sent_tokenize(context)\n",
    "        for q in para[\"qas\"]:\n",
    "            question = q[\"question\"]\n",
    "            if q[\"answers\"]:\n",
    "                answer = q[\"answers\"][0][\"text\"]\n",
    "            else:\n",
    "                continue\n",
    "            most_sim = min([(w2vec_model.wmdistance(question, sent), sent) for sent in sents], key=lambda x:x[0])\n",
    "            ans_in_sim.append(answer in most_sim[1])\n",
    "ans_in_sim = np.array(ans_in_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions evaluated: 86821\n",
      "Number of questions where the most similar sentence contained the correct answer: 49091\n",
      "Percentage correct: 0.5654277191002177\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of questions evaluated:\", ans_in_sim.shape[0])\n",
    "print(\"Number of questions where the most similar sentence contained the correct answer:\", np.sum(ans_in_sim))\n",
    "print(\"Percentage correct:\", np.sum(ans_in_sim)/ans_in_sim.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanal",
   "language": "python",
   "name": "dataanal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
